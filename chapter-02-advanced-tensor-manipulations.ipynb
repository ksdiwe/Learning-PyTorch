{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T10:55:24.687255Z",
     "iopub.status.busy": "2025-11-22T10:55:24.686771Z",
     "iopub.status.idle": "2025-11-22T10:55:24.693691Z",
     "shell.execute_reply": "2025-11-22T10:55:24.692937Z",
     "shell.execute_reply.started": "2025-11-22T10:55:24.687229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D tensor:\n",
      "tensor([10, 11, 12, 13, 14])\n",
      "\n",
      "First element (x_1d[0]): 10, Type: <class 'torch.Tensor'>\n",
      "Last element (x_1d[-1]): 14\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 1D tensor\n",
    "x_1d = torch.tensor([10, 11, 12, 13, 14])\n",
    "print(f\"Original 1D tensor:\\n{x_1d}\")\n",
    "\n",
    "# Access the first element\n",
    "first_element = x_1d[0]\n",
    "print(f\"\\nFirst element (x_1d[0]): {first_element}, Type: {type(first_element)}\")\n",
    "\n",
    "# Access the last element\n",
    "last_element = x_1d[-1]\n",
    "print(f\"Last element (x_1d[-1]): {last_element}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T10:55:32.724006Z",
     "iopub.status.busy": "2025-11-22T10:55:32.723603Z",
     "iopub.status.idle": "2025-11-22T10:55:32.746949Z",
     "shell.execute_reply": "2025-11-22T10:55:32.746008Z",
     "shell.execute_reply.started": "2025-11-22T10:55:32.723949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified tensor:\n",
      "tensor([ 10, 110,  12,  13,  14])\n"
     ]
    }
   ],
   "source": [
    "# Modify an element\n",
    "x_1d[1] = 110\n",
    "print(f\"\\nModified tensor:\\n{x_1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T10:58:10.197639Z",
     "iopub.status.busy": "2025-11-22T10:58:10.197284Z",
     "iopub.status.idle": "2025-11-22T10:58:10.215077Z",
     "shell.execute_reply": "2025-11-22T10:58:10.214035Z",
     "shell.execute_reply.started": "2025-11-22T10:58:10.197613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "Element at [0, 1]: 2\n",
      "\n",
      "First row (x_2d[0]): tensor([1, 2, 3])\n",
      "Second column (x_2d[:, 1]): tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor (e.g., a small matrix)\n",
    "x_2d = torch.tensor([[1, 2, 3],\n",
    "                     [4, 5, 6],\n",
    "                     [7, 8, 9]])\n",
    "print(f\"Original 2D tensor:\\n{x_2d}\")\n",
    "\n",
    "# Access the element at row 0, column 1\n",
    "element_0_1 = x_2d[0, 1]\n",
    "print(f\"\\nElement at [0, 1]: {element_0_1}\")\n",
    "\n",
    "# Access the entire first row (index 0)\n",
    "first_row = x_2d[0] # or x_2d[0, :]\n",
    "print(f\"\\nFirst row (x_2d[0]): {first_row}\")\n",
    "\n",
    "# Access the entire second column (index 1)\n",
    "second_col = x_2d[:, 1]\n",
    "print(f\"Second column (x_2d[:, 1]): {second_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T10:58:20.277433Z",
     "iopub.status.busy": "2025-11-22T10:58:20.277129Z",
     "iopub.status.idle": "2025-11-22T10:58:20.283371Z",
     "shell.execute_reply": "2025-11-22T10:58:20.282540Z",
     "shell.execute_reply.started": "2025-11-22T10:58:20.277410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified 2D tensor:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4, 55,  6],\n",
      "        [ 7,  8,  9]])\n"
     ]
    }
   ],
   "source": [
    "# Modify an element\n",
    "x_2d[1, 1] = 55\n",
    "print(f\"\\nModified 2D tensor:\\n{x_2d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:18:07.267197Z",
     "iopub.status.busy": "2025-11-22T12:18:07.266903Z",
     "iopub.status.idle": "2025-11-22T12:18:07.276317Z",
     "shell.execute_reply": "2025-11-22T12:18:07.275185Z",
     "shell.execute_reply.started": "2025-11-22T12:18:07.267180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "Slice y_1d[2:5]: tensor([2, 3, 4])\n",
      "Slice y_1d[:4]: tensor([0, 1, 2, 3])\n",
      "Slice y_1d[6:]: tensor([6, 7, 8, 9])\n",
      "Slice y_1d[::2]: tensor([0, 2, 4, 6, 8])\n",
      "Slice y_1d[1:8:2]: tensor([1, 3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# Slicing Tensors\n",
    "# The syntax is start:stop:step, \n",
    "# where start is inclusive, stop is exclusive, and step defines the interval.\n",
    "\n",
    "import torch\n",
    "# Create a 1D tensor\n",
    "y_1d = torch.arange(10) # Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(f\"Original 1D tensor: {y_1d}\")\n",
    "\n",
    "# Select elements from index 2 up to (not including) index 5\n",
    "slice1 = y_1d[2:5]\n",
    "print(f\"\\nSlice y_1d[2:5]: {slice1}\")\n",
    "\n",
    "# Select elements from the beginning up to index 4\n",
    "slice2 = y_1d[:4]\n",
    "print(f\"Slice y_1d[:4]: {slice2}\")\n",
    "\n",
    "# Select elements from index 6 to the end\n",
    "slice3 = y_1d[6:]\n",
    "print(f\"Slice y_1d[6:]: {slice3}\")\n",
    "\n",
    "# Select every second element\n",
    "slice4 = y_1d[::2]\n",
    "print(f\"Slice y_1d[::2]: {slice4}\")\n",
    "\n",
    "# Select elements from index 1 to 7, with a step of 2\n",
    "slice5 = y_1d[1:8:2]\n",
    "print(f\"Slice y_1d[1:8:2]: {slice5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:18:21.012990Z",
     "iopub.status.busy": "2025-11-22T12:18:21.012745Z",
     "iopub.status.idle": "2025-11-22T12:18:21.023279Z",
     "shell.execute_reply": "2025-11-22T12:18:21.022287Z",
     "shell.execute_reply.started": "2025-11-22T12:18:21.012973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3222641398.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reverse the tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslice6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Slice y_1d[::-1]: {slice6}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "# Reverse the tensor\n",
    "slice6 = y_1d[::-1]\n",
    "print(f\"Slice y_1d[::-1]: {slice6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:21:31.877469Z",
     "iopub.status.busy": "2025-11-22T12:21:31.877200Z",
     "iopub.status.idle": "2025-11-22T12:21:31.890952Z",
     "shell.execute_reply": "2025-11-22T12:21:31.890275Z",
     "shell.execute_reply.started": "2025-11-22T12:21:31.877450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "slice6 = torch.flip(y_1d, dims=[0])\n",
    "print(slice6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:24:34.370834Z",
     "iopub.status.busy": "2025-11-22T12:24:34.370502Z",
     "iopub.status.idle": "2025-11-22T12:24:34.383441Z",
     "shell.execute_reply": "2025-11-22T12:24:34.382678Z",
     "shell.execute_reply.started": "2025-11-22T12:24:34.370810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D tensor:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x4 tensor\n",
    "x_2d = torch.tensor([[ 0,  1,  2,  3],\n",
    "                     [ 4,  5,  6,  7],\n",
    "                     [ 8,  9, 10, 11]])\n",
    "print(f\"Original 2D tensor:\\n{x_2d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:25:50.522639Z",
     "iopub.status.busy": "2025-11-22T12:25:50.522347Z",
     "iopub.status.idle": "2025-11-22T12:25:50.547031Z",
     "shell.execute_reply": "2025-11-22T12:25:50.546240Z",
     "shell.execute_reply.started": "2025-11-22T12:25:50.522617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slice x_2d[0:2, 1:3]:\n",
      "tensor([[1, 2],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Select the first two rows and columns 1 and 2\n",
    "sub_tensor1 = x_2d[0:2, 1:3]\n",
    "print(f\"\\nSlice x_2d[0:2, 1:3]:\\n{sub_tensor1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:30:25.337558Z",
     "iopub.status.busy": "2025-11-22T12:30:25.337246Z",
     "iopub.status.idle": "2025-11-22T12:30:25.343877Z",
     "shell.execute_reply": "2025-11-22T12:30:25.343096Z",
     "shell.execute_reply.started": "2025-11-22T12:30:25.337540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slice x_2d[:, -2:]:\n",
      "tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Select all rows, but only the last two columns\n",
    "sub_tensor2 = x_2d[:, -2:]\n",
    "print(f\"\\nSlice x_2d[:, -2:]:\\n{sub_tensor2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:31:18.111246Z",
     "iopub.status.busy": "2025-11-22T12:31:18.110390Z",
     "iopub.status.idle": "2025-11-22T12:31:18.117319Z",
     "shell.execute_reply": "2025-11-22T12:31:18.116477Z",
     "shell.execute_reply.started": "2025-11-22T12:31:18.111214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slice x_2d[0, 1:]:\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Select the first row, columns 1 to the end\n",
    "sub_tensor3 = x_2d[0, 1:]\n",
    "print(f\"\\nSlice x_2d[0, 1:]:\\n{sub_tensor3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:31:43.982239Z",
     "iopub.status.busy": "2025-11-22T12:31:43.981208Z",
     "iopub.status.idle": "2025-11-22T12:31:43.987573Z",
     "shell.execute_reply": "2025-11-22T12:31:43.986814Z",
     "shell.execute_reply.started": "2025-11-22T12:31:43.982201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slice x_2d[::2, :]:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Select rows 0 and 2 (using step), all columns\n",
    "sub_tensor4 = x_2d[::2, :]\n",
    "print(f\"\\nSlice x_2d[::2, :]:\\n{sub_tensor4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returned tensor often shares the same underlying storage as the original tensor. Modifying the slice will modify the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x_2d before modifying slice:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n",
      "Slice after modification:\n",
      "tensor([[101,   2],\n",
      "        [  5,   6]])\n",
      "\n",
      "Original x_2d after modifying slice:\n",
      "tensor([[  0, 101,   2,   3],\n",
      "        [  4,   5,   6,   7],\n",
      "        [  8,   9,  10,  11]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original x_2d before modifying slice:\\n{x_2d}\")\n",
    "\n",
    "# Get a slice\n",
    "sub_tensor = x_2d[0:2, 1:3]\n",
    "\n",
    "# Modify the slice\n",
    "sub_tensor[0, 0] = 101\n",
    "\n",
    "print(f\"\\nSlice after modification:\\n{sub_tensor}\")\n",
    "print(f\"\\nOriginal x_2d after modifying slice:\\n{x_2d}\") # Note the change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[101,   2],\n",
      "        [  5,   6]])\n"
     ]
    }
   ],
   "source": [
    "# If you need a copy that doesn't share memory, use .clone() on the slice\n",
    "sub_tensor_copy = x_2d[0:2, 1:3].clone()\n",
    "print(sub_tensor_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Indexing (Masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "data = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(f\"Original data tensor:\\n{data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boolean mask (data > 3):\n",
      "tensor([[False, False],\n",
      "        [False,  True],\n",
      "        [ True,  True]])\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask (e.g., select elements greater than 3)\n",
    "mask = data > 3\n",
    "print(f\"\\nBoolean mask (data > 3):\\n{mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elements selected by mask:\n",
      "tensor([4, 5, 6])\n",
      "Shape of selected elements: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Apply the mask\n",
    "selected_elements = data[mask]\n",
    "print(f\"\\nElements selected by mask:\\n{selected_elements}\")\n",
    "print(f\"Shape of selected elements: {selected_elements.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after setting elements <= 3 to zero:\n",
      "tensor([[0, 0],\n",
      "        [0, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Modify elements based on a condition\n",
    "data[data <= 3] = 0\n",
    "print(f\"\\nData after setting elements <= 3 to zero:\\n{data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Boolean indexing typically returns a **1-dimensional tensor** containing all the selected elements. It does not preserve the original shape, unlike slicing. Also, boolean indexing usually creates a copy, not a view._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row mask (data[:, 0] > 2): tensor([False, False,  True])\n",
      "\n",
      "Rows where first column > 2:\n",
      "tensor([[5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Select rows where the first column is greater than 2\n",
    "row_mask = data[:, 0] > 2\n",
    "print(f\"\\nRow mask (data[:, 0] > 2): {row_mask}\")\n",
    "\n",
    "selected_rows = data[row_mask, :] # Use ':' for selecting all columns in the chosen rows\n",
    "# Or simply: data[row_mask] - PyTorch often infers the full row selection\n",
    "print(f\"\\nRows where first column > 2:\\n{selected_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer Array Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D tensor: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10, 20) # Tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "print(f\"Original 1D tensor: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected elements using indices tensor([0, 4, 2, 2]): tensor([10, 14, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.tensor([0, 4, 2, 2]) # Note the repeated index 2\n",
    "selected = x[indices]\n",
    "print(f\"\\nSelected elements using indices {indices}: {selected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original 2D tensor:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# For 2D tensors\n",
    "y = torch.arange(12).reshape(3, 4)  \n",
    "print(f\"\\nOriginal 2D tensor:\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected rows using indices tensor([0, 2]):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Select specific rows\n",
    "row_indices = torch.tensor([0, 2])\n",
    "selected_rows = y[row_indices] # Selects rows 0 and 2\n",
    "print(f\"\\nSelected rows using indices {row_indices}:\\n{selected_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected columns using indices tensor([1, 3]):\n",
      "tensor([[ 1,  3],\n",
      "        [ 5,  7],\n",
      "        [ 9, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns\n",
    "col_indices = torch.tensor([1, 3])\n",
    "selected_cols = y[:, col_indices] # Selects columns 1 and 3 from all rows\n",
    "print(f\"\\nSelected columns using indices {col_indices}:\\n{selected_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected specific elements using (row_idx, col_idx):\n",
      "tensor([1, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "# Select specific elements using pairs of indices\n",
    "row_idx = torch.tensor([0, 1, 2])\n",
    "col_idx = torch.tensor([1, 3, 0])\n",
    "selected_elements = y[row_idx, col_idx] # Selects (0,1), (1,3), (2,0) -> [1, 7, 8]\n",
    "print(f\"\\nSelected specific elements using (row_idx, col_idx):\\n{selected_elements}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like boolean indexing, integer array indexing usually returns a new tensor (a copy), not a view into the original tensor's storage. The shape of the output depends on the indexing method. When selecting full rows or columns, the other dimensions are preserved. When providing index arrays for multiple dimensions *(like y[row_idx, col_idx])*, the result is often a 1D tensor corresponding to the selected elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Rearranging Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chaning Shape with `view()` and `reshape()`\n",
    "Both view() and reshape() allow you to change the dimensions of a tensor, provided the total number of elements remains constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "Original shape: torch.Size([12])\n",
      "Is contiguous? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a contiguous tensor\n",
    "x = torch.arange(12) # tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
    "print(f\"Original tensor: {x}\")\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Is contiguous? {x.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor after view(3, 4):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "New shape: torch.Size([3, 4])\n",
      "Shares storage with x? True\n",
      "Is y contiguous? True\n"
     ]
    }
   ],
   "source": [
    "# Reshape using view()\n",
    "y = x.view(3, 4)\n",
    "print(\"\\nTensor after view(3, 4):\")\n",
    "print(y)\n",
    "print(f\"New shape: {y.shape}\")\n",
    "# Check if they share memory\n",
    "print(f\"Shares storage with x? {y.untyped_storage().data_ptr() == x.untyped_storage().data_ptr()}\") \n",
    "print(f\"Is y contiguous? {y.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor after view(2, 6):\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "New shape: torch.Size([2, 6])\n",
      "Shares storage with x? True\n",
      "Is z contiguous? True\n"
     ]
    }
   ],
   "source": [
    "# Try another view\n",
    "z = y.view(2, 6)\n",
    "print(\"\\nTensor after view(2, 6):\")\n",
    "print(z)\n",
    "print(f\"New shape: {z.shape}\")\n",
    "print(f\"Shares storage with x? {z.untyped_storage().data_ptr() == x.untyped_storage().data_ptr()}\")\n",
    "print(f\"Is z contiguous? {z.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, using `-1` in a `view()` call tells PyTorch:\n",
    "\n",
    "> **â€œYou figure out this dimension automatically based on the total number of elements.â€**\n",
    "\n",
    "Itâ€™s like saying auto-calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor after view(2, 2, -1):\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "New shape: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Using -1 for inference\n",
    "w = x.view(2, 2, -1) # Infers the last dimension to be 3 (12 / (2*2) = 3)\n",
    "print(\"\\nTensor after view(2, 2, -1):\")\n",
    "print(w)\n",
    "print(f\"New shape: {w.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  A Trick to Understand Any view(a,b,c) Instantly\n",
    "* a = number of groups\n",
    "* b = number of rows per group\n",
    "* c = number of columns per row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Is b contiguous? False\n",
      "\n",
      "Error trying b.view(12): view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    }
   ],
   "source": [
    "# Example of view() failing on a non-contiguous tensor\n",
    "a = torch.arange(12).view(3, 4)\n",
    "b = a.t() # Transpose creates a non-contiguous tensor\n",
    "print(f\"\\nIs b contiguous? {b.is_contiguous()}\")\n",
    "\n",
    "try:\n",
    "    c = b.view(12)\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nError trying b.view(12): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original non-contiguous tensor b:\n",
      "tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n",
      "Shape of b: torch.Size([4, 3])\n",
      "Is b contiguous? False\n"
     ]
    }
   ],
   "source": [
    "# using reshape()\n",
    "\n",
    "# Using reshape() on the non-contiguous tensor 'b'\n",
    "print(f\"\\nOriginal non-contiguous tensor b:\\n{b}\")\n",
    "print(f\"Shape of b: {b.shape}\")\n",
    "print(f\"Is b contiguous? {b.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor c after b.reshape(12):\n",
      "tensor([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])\n",
      "Shape of c: torch.Size([12])\n",
      "Is c contiguous? True\n"
     ]
    }
   ],
   "source": [
    "# Reshape works even if 'b' is not contiguous\n",
    "c = b.reshape(12)\n",
    "print(f\"\\nTensor c after b.reshape(12):\\n{c}\")\n",
    "print(f\"Shape of c: {c.shape}\")\n",
    "print(f\"Is c contiguous? {c.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shares storage with b? False\n"
     ]
    }
   ],
   "source": [
    "# Check if 'c' shares storage with 'b'. It likely won't because reshape probably copied.\n",
    "print(f\"Shares storage with b? {c.storage().data_ptr() == b.storage().data_ptr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor d after b.reshape(2, -1):\n",
      "tensor([[ 0,  4,  8,  1,  5,  9],\n",
      "        [ 2,  6, 10,  3,  7, 11]])\n",
      "Shape of d: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Reshape can also infer dimensions with -1\n",
    "d = b.reshape(2, -1) # Infers the last dimension to be 6\n",
    "print(f\"\\nTensor d after b.reshape(2, -1):\\n{d}\")\n",
    "print(f\"Shape of d: {d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `view()` if you are certain the tensor is contiguous and you want to guarantee no data copy occurs for maximum performance.\n",
    "* Use `reshape()` for an approach that works on both contiguous and non-contiguous tensors. It will return a view if possible, otherwise it makes a copy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rearranging Dimensions with `permute()`\n",
    "\n",
    "explicitly swaps the dimensions themselves. It doesn't change the total number of elements or the shape in terms of the number of elements along each axis, but it changes which axis corresponds to which original dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor (e.g., representing C, H, W)\n",
    "image_tensor = torch.randn(3, 32, 32) # Channels, Height, Width\n",
    "print(f\"Original shape: {image_tensor.shape}\") # torch.Size([3, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuted shape: torch.Size([32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Permute to (Height, Width, Channels)\n",
    "permuted_tensor = image_tensor.permute(1, 2, 0) # Specify new order: Dim 1, Dim 2, Dim 0\n",
    "print(f\"Permuted shape: {permuted_tensor.shape}\") # torch.Size([32, 32, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is permuted_tensor contiguous? False\n"
     ]
    }
   ],
   "source": [
    "# Permute usually returns a non-contiguous view\n",
    "print(f\"Is permuted_tensor contiguous? {permuted_tensor.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after permuting back: torch.Size([3, 32, 32])\n",
      "Is original_again contiguous? True\n"
     ]
    }
   ],
   "source": [
    "# Permuting back\n",
    "original_again = permuted_tensor.permute(2, 0, 1) # Back to C, H, W\n",
    "print(f\"Shape after permuting back: {original_again.shape}\") # torch.Size([3, 32, 32])\n",
    "print(f\"Is original_again contiguous? {original_again.is_contiguous()}\") # Might still be non-contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shares storage with original? True\n"
     ]
    }
   ],
   "source": [
    "# Check storage sharing\n",
    "print(f\"Shares storage with original? {original_again.storage().data_ptr() == image_tensor.storage().data_ptr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Is contiguous_permuted contiguous? True\n"
     ]
    }
   ],
   "source": [
    "# Make the permuted tensor contiguous\n",
    "contiguous_permuted = permuted_tensor.contiguous()\n",
    "print(f\"\\nIs contiguous_permuted contiguous? {contiguous_permuted.is_contiguous()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after flattening: torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "# Now view() can be used safely\n",
    "flattened_permuted = contiguous_permuted.view(-1)\n",
    "print(f\"Shape after flattening: {flattened_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining and Splitting Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tensors\n",
    "\n",
    "PyTorch offers two primary ways to join tensors: concatenation (torch.cat) and stacking (torch.stack). The main difference lies in whether they operate along an existing dimension or introduce a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A (Shape: torch.Size([2, 3])):\n",
      "tensor([[-0.2501,  0.9695,  0.1741],\n",
      "        [-0.1746, -0.7158,  0.1631]])\n",
      "Tensor B (Shape: torch.Size([2, 3])):\n",
      "tensor([[-1.5208,  0.1634,  2.1580],\n",
      "        [-0.3208,  1.3212,  0.2043]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenation with torch.cat\n",
    "# The torch.cat function joins a sequence of tensors along an existing dimension. \n",
    "\n",
    "# Create two tensors\n",
    "tensor_a = torch.randn(2, 3)\n",
    "tensor_b = torch.randn(2, 3)\n",
    "print(f\"Tensor A (Shape: {tensor_a.shape}):\\n{tensor_a}\")\n",
    "print(f\"Tensor B (Shape: {tensor_b.shape}):\\n{tensor_b}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated along dim=0 (Shape: torch.Size([4, 3])):\n",
      "tensor([[-0.2501,  0.9695,  0.1741],\n",
      "        [-0.1746, -0.7158,  0.1631],\n",
      "        [-1.5208,  0.1634,  2.1580],\n",
      "        [-0.3208,  1.3212,  0.2043]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along dimension 0 (rows)\n",
    "# Resulting shape: (2+2, 3) = (4, 3)\n",
    "cat_dim0 = torch.cat((tensor_a, tensor_b), dim=0)\n",
    "print(f\"Concatenated along dim=0 (Shape: {cat_dim0.shape}):\\n{cat_dim0}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated along dim=1 (Shape: torch.Size([2, 6])):\n",
      "tensor([[-0.2501,  0.9695,  0.1741, -1.5208,  0.1634,  2.1580],\n",
      "        [-0.1746, -0.7158,  0.1631, -0.3208,  1.3212,  0.2043]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along dimension 1 (columns)\n",
    "# Tensors must match in other dimensions (dim 0)\n",
    "# Resulting shape: (2, 3+3) = (2, 6)\n",
    "\n",
    "cat_dim1 = torch.cat((tensor_a, tensor_b), dim=1)\n",
    "print(f\"Concatenated along dim=1 (Shape: {cat_dim1.shape}):\\n{cat_dim1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenated 3D along dim=0 (Shape: torch.Size([2, 2, 3]))\n"
     ]
    }
   ],
   "source": [
    "# Example with 3D tensors\n",
    "# 3D tensor --> (batch_size, rows, column)\n",
    "\n",
    "tensor_c = torch.randn(1, 2, 3)\n",
    "tensor_d = torch.randn(1, 2, 3)\n",
    "# Concatenate along dim 0 (batch dimension)\n",
    "# Resulting shape: (1+1, 2, 3) = (2, 2, 3)\n",
    "cat_3d_dim0 = torch.cat((tensor_c, tensor_d), dim=0)\n",
    "print(f\"\\nConcatenated 3D along dim=0 (Shape: {cat_3d_dim0.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor E (Shape: torch.Size([2, 3])):\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Tensor F (Shape: torch.Size([2, 3])):\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking with torch.stack \n",
    "# torch.stack joins a sequence of tensors along a new dimension\n",
    "# For stack to work, all tensors in the input sequence must have the exact same shape.\n",
    "\n",
    "import torch\n",
    "# Create two tensors with the same shape\n",
    "tensor_e = torch.arange(6).reshape(2, 3)\n",
    "tensor_f = torch.arange(6, 12).reshape(2, 3)\n",
    "print(f\"Tensor E (Shape: {tensor_e.shape}):\\n{tensor_e}\")\n",
    "print(f\"Tensor F (Shape: {tensor_f.shape}):\\n{tensor_f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked along new dim=0 (Shape: torch.Size([2, 2, 3])):\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack along a new dimension 0\n",
    "# Resulting shape: (2, 2, 3)\n",
    "\n",
    "stack_dim0 = torch.stack((tensor_e, tensor_f), dim=0)\n",
    "print(f\"Stacked along new dim=0 (Shape: {stack_dim0.shape}):\\n{stack_dim0}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding:\n",
    "\n",
    "Visualization:\n",
    "[\n",
    "  tensor_e,\n",
    "  tensor_f\n",
    "]\n",
    "\n",
    "This new outer structure has size 2, because you stacked 2 tensors.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACnCAYAAACCVlwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABi0SURBVHhe7d1NbBNnwgfwfxLywRI6AYV40Jtlk25cq0i77SGgijgXlqVquOw2QYpclUrRSpEPRVH2xgHLHHJ7LYserEirSF2pFhLObi8BUQWklZ2qC9nDW6qyrr1sS71iHFDJQMgSQuA9jD9mHn/EdmzHzvx/1UjNM4/9jCfO/P18DG7o7e19hSKsrq6KRURERHWrUSwgIiIyEwYhERGZGoOQiIhMjUFIRESmxiAkIiJTYxASEZGpMQiJiMjUGIRERGRqDEIiIjI1BiEREZkag5CIiEyNQUhERKbGICQiIlNjEBIRkakxCImIyNQYhEREZGoMQiIiMrXaCsLxAMJKEB6x3Gy8QSjhAJxiORERlV0NBaEHQbcdWPBjUtxlNhN+hGCHK2T6jwRERBXX0Nvb+0oszGd1dVUsKgMnAmEX7A/8kO1iDErwdA7jWHPy5yf48sFlTL4w1tq66rTz7p7TcL+2V1eSqx0PgooDXQtu2IZ94k4iIiqT2ghCbxDKaBdCLhtGpo27PpbG8AH+hnfUfwGpIFHx2f0v8Imx6pZUqx1Rvnacs2G4BpbglwfZSyYiqpAaGBp1IvCeFYjOZYQgAHyizqTCCQCurd3FE3Sjv9VQbcuq1Y5Ia0dC7y5xD+AbnkMEVpya5WwhEVGl1EAQWmGRgMiiOfs8H+95C3vX7+JaxtAoAEziVhSQLFZxBxERlcn2B+H4IXRBRfyOuCO7d1tfx17EsLgm7imvSrbz7p7T+OrgGL46OIYPfhbDZw//gWtipYRIXAUOHOIKUiKiCtn+IHzTAkksy6X1JNyv7cWTx3/PmE8rqwq3c+3pZbxzf0bbfgI+ODiGT/MNwUoWsE9IRFQZ2x+Ed+JQxbJsWk/iq/3dePJ4Fr99WtAjSlOtdpLWvsBnq4Ct7ZfinjQ1johYRkREZbH9QTh9D0uQYHlT3KFTrXCqVjsGEnqbgScvHoo7AABWiwQ8uAfeQEFEVBnbH4SIIK4C1v4cN48XGk7jAYQVpfR/kaVa7Qje3XMSx5qf4PZatjY9ONJn3oVERETVUOP3EYo3uevFhHvvtBvQrQAil2QMThgqb6Ja7STuV/yZrmD9/+DKtVjGG4QyCt5HSERUQbURhHn/ZZnCaTegI0uglld12uG/LENEVA01MDQKAD6M2PyI9DkQLvnmcQ8cAxKg3sb1ioUTqtSOE4GwA9aonyFIRFRhNdIjTBgPIOy2YK7IoUBPSIGjD0B0az3KzVSrHXiDUN6Lw20b4SIZIqIKq60gJCIiqrIaGRolIiLaHgxCIiIyNQYhERGZGoOQiIhMjUFIRESmxiAkIiJTYxASEZGpMQiJiMjUGIRERGRqDEIiIjI1BiEREZkag5CIiEytjoLQg2CZvhU+v2q1sznnbBhBr1hKRETlVCdBmPhWeMkOV0VDqlrtbE778l8J1lGFYUhEVEF1EISJcFJVaP9VKqSq1c7mtBAEVBVQVZVhSERUQTUfhM7ZU7BG/ZA9twEsYc7mRgh2OMocDNVqZ3MeOAaAkMuGuQcAvvFCvhSB9b3tCWUiop2ufr6Yt8Rvry9atdopgCek4FTcDdswv6eeiKhSar5HSEREVEkMQiIiMjUGIRERmRqDkIiITI1BSEREpsYgJCIiU6uf2yeIiIgqgD1CIiIyNQYhERGZGoOQiIhMjUFIRESmxiAkIiJTYxASEZGpMQiJiMjUGIRERGRqDEIiIjI1BiEREZkag5CIiEyNQVjDPCEF4VmnWExERGXEICQiIlOrnyD0BqEoQXjE8nKrVjtERFQT6icIiYiIKoBBSFXiQVBRttzb9oQUKIqCoFfcUx7O2TAURWtDUcIIjIs16kvT0OewnJ9PbJ9jT7dYg4gYhEQ6vmEbZFmG7ApBFXcW6N09p/HVwTHddhqeXWKt6ti48jvEL5xAfOYm1sWdRAQwCKl6JjEoy5DlQUyKu4owaZchyzIGJ8Q9tePa08t45/5ManM9Bo4dOImPxYpEVBMYhEQVdm3tLp5AQu829QqJKD8GIeXnDermzDLn+DwhBUrIA4wHEM5ax4lAWPf4cABZ74zMaEfbkvdRbjp3l1ztaziOzLlE4/Mkjr3CPt7zFvau38W1F+KezRnn+OZhOTuFJt3+ljO6fefnYTkjnphN9Psy5w77fbCc96El+f9np9CSPA7h/7VjGYd0fh5S/3HsOZvvWLR6+uPdP3RcqENUfQzCGicNuAwX7u++ywwL4xZDLKNM2Aq9+HuDUEa7EHJpw5GyLMMftcIhLnjpc0BxWzAny5BlN0KqFY5UGz6M2LTHuhdyzLqNBxAetSJyKdmOHxEA6oIbtmEfUPDcnRWO1HFo7VlHdcfqDWIC3tRrkV0hqH2OivyjBfp5wg9+FsNnD/+Ba2KlTbScmUdnP7Ayc0Kb57twAvGL57Ch27+v4yYeJvdduIxnPaezBNAWdRzFvs6r2jxjx1Hs6/sWD2duYr3jMNp0Ado2dA67vkwcy8xNrPechtSf3Hsce86eRtPiVPq1XDiBn67cSD8B0TZhENaw5HyYfnvjjcwy49aN7owyYbMXMkvnROA9KxCdw8h0unTS7kcEVhwx9LQi8Kfm/ny4/o0KHDiUveeXzZsWSIjgVmrebxK3ooBksRrrbUpFyJWeg/T9uGTcPTGYClYAwPR13M6dqltimCf8Cfjg4Bg+bRVr5dE9hfYe4NmV3+FpTNyp2/9lOhiBaahXIkDP21pvrmxWsHIj+SZYwcpf9G2mrS9OQV1M/BD7IWud5r4Thh4tUS1gEFJeajwiFgEAun6uizk1Dn0t37ANsm0EusjJ704cqiFcPTjSl7vt0iVv4UhuLtglsU4FrH2Bz1YBW9svxT2bWMELRSzTy7X/IJpr7jaJG3h6cQorOIrOHMO8RNuFQUglWfqx4JgrmHU0GVAOdOmGRcvDiUDYAWvUr+sduxGqUI/QSEJvM/DkxUNxR4Xcx3q2XuS2u4GnF5PDoolQZBhSDWAQUg7aEKc0MGFYmOIJOWBVQ/CX8fYFz4d2SIaAksscgtk5Zyeq0iN8d89JHGt+gttrRaRubB5ry+1oH0ssWhEl97+vD5JxSENWrC9exnND5TyUR1hHO3bJiZ/7fbAMFTskXYobeBZdEQuJtgWDkHLyDdvgXgDs7vRwouNACO5ihj11qzhdAxIg2eFSFMPKz0m7H5E+R+aintQKU93KU7cdEqTUMRW+0MWHkasRbWFP8ngsc/BH9XXK0Q7wsaS/mX4M7t134bp/GZNFrRrVek+PvrdiX9ZVo1mGGs9ri1HSC1B0qzjHjqIZ7WgfE1Zrxs5BXVxB21Ci3hDwqCI332euGO3sv49HusU/RNulobe395VYmM/q6qpYVB3eIJRR6BZlVEi12qEEJwJhF+wP/MIiHg+CFRkiJSIyYo+QapP3CKwVmoskItJjENI282HEo93PZxgWTdy/WMv/lBoR7Qz1MzRKRERUAewREhGRqTEIiYjI1BiERERkagxCIiIyNQYhERGZGoOQiIhMjUFIRESmxiAkIiJTYxCKxgMIi9/ATkREOxaDkIiITK1+gtAbhMKeGhERlVn9BCEREVEFMAipSjwIKsqWe/WekPbtFEGvuKc8nLNh3bdgpL88mIh2LgYhkY5v2AZZliG7QlDFnQWT4OnUf0v9aXh2iXWIqFYwCKlKJjEoy5DlQei/h75Yk3YZslzb31P4sTSMY+t/wzv3Z/DO/Rm4HgPHDpzEx2JFIqoJDEKiMvtEncE76r9SP19bu4sn6EZ/q6EaEdUIBiHl5w0avzlemOPzhBQoIU/i/stsdZwIhHWPDwfg1D0+JaMdbQvParU3nbtLrio2HEfmXKLxeRLHXpPGIZ2fh9QPNA19Dsv5eW07Y3zhLWcS5Vn2t5yZx/6h44b6mvRz63/WP0/2xxHtTAzCrKxw6C+WsVjGBVrcvvsus8y4xRDLKBO2f9/LLBO2srRT6MXfG4Qy2oWQSxuOlGUZ/qgVDnHBS58DituCOVmGLLsRUq1wpNrwYcSmPda9kGPWbTyA8KgVkUvJdvyIAFAX3LAN+4CC5+6scKSOQ2vPOqo7Vm8QE/CmXovsCkHtc6TCtlLebX0dexHD4pq4Z3NtQ/Po7LyK+IUTiM/cxHrP6VSAtZyZx76Om3h44YS2/8JlPOs5nQrDjYcraO60Gp8QALp/gSas4IUCAMex5+xpNC1OJZ5D2366ckN8FNGOxSAUTY/AlrxQJrfubuPPWbY33sgsM27d6M4oE7beQ5llwlaWduyFzNI5EXjPCkTnMDKdLp20+xGBFUcMPa0I/Km5Px+uf6MCBw5l7/ll86YFEiK4lZr3m8StKCBZslzE81IRcqXnIH0/Lhl3TwymghUAMH0dt3Onanm0noT7tb148vjv+ETcV4jvLyP+58QvIDaPtWWgqes40D2F9h7g2ZfnsJGqPA31SgToeRstyaKOX6AJAPp9sJz3pctxH+ux1A9o7juh1SMyIQYh5aXGI2IRAKDr57qYU+PQ1/IN2yDbRqCLnPzuxKEawtWDI3252y5d8haO5OaCXRLrlFHrSXy1vxtPHs/it09LS9z1h/pzcANPL+p7a8leneggmruBjaX7QMc+NAFoOXwQ68tW7O4HIO9D8/KjRIDewNOLU1jBUXQmh0bPTjEUyVQYhFSSpR8LjrmCWUeTAeVAl25YtDycCIQdsEb9ut6xG6HS8mlzZQjB0iV6e8ojrAMAxrG741uoX0bQdngcTV0HgeUfdD1JLWC1YdFEKDIMyUQYhJSDNsQpDUwYFqZ4Qg5Y1RD8Zbx9wfOhHZIhoOQyh2B2ztmJyvQIqxGCsXmsLbej/X19YI1DGrJiffEyngNA7Ads4CCah95GU3QeG4uXsdLxNtoyepp6N/AsuiIWEu1oDELKyTdsg3sBsLvTw4mOAyG4ixn21K3idA1IgGSHS1EMKz8n7X5E+hyZi3pSK0x1K0/ddkiQUsdU+EIXH0auRrSFPcnjsczBH9XXKUc7Ejx7uwEAe18b1t1UP4avDpbzXsIsQ5rntUUv6aHTCF4st6O9H1i5ciMRcgfR3t+OjaVkncwVo5399/Hoon7ukWhna+jt7X0lFuazuroqFlWHNwhlFLpFGbQzOBEIu2B/4BcW8XgQrMgQKRGREXuEVJu8R2Ct0FwkEZEeg5C2mQ8jHu1+PsOwaOL+xVr+p9SIaGeon6FRIiKiCmCPkIiITI1BSEREpsYgJCIiU2MQEhGRqTEIiYjI1BiERERkagxCIiIyNQYhERGZWv0E4XgAYfGb0YmIiLaofoKQiIioAhiERERkagxCIiIyNQYh1SkPgoqCoDd7uVIn88mekPZtG5mvg8rFORvWfclzIbQvK94/dFzcsXONBxDWfVl2Ps7ZcJFfVl37GIREVDu8wbr5EFM9uT70UbkwCGmHmcSgLEOWB6H/vvtaNWmXIcv83kWqH75hG2RZhm1453xpNoOQiIhMjUFIOX009F98fXYdH/Wv4evzTxPbf/GnbmM995nkPm37vD+55wU+z1IfANC/hq/Pr8EtlueRnE/TNgeshr1OBMK6/RlzQh4ElTAC3gDCigJF/H/d3IixHWFIKjl0N558bJY6unmU9GYc7jPuzzE3I7RhrKe93vCs03i8Ga+7MBnHq3ue9Bxbcv5VPBZN3vOm1dA93vgcqfZHrQCscOjqiXNRm7YjnDfXgCRUKMzGErDn7Dws5xPbmeQL1uYQ0z8ndE9hfwlzi+LrSZ371OvQ3uvW0Sx1EjJ+f6Esg8t530+i9O8qdX69wfznPTWEK/wtisciPE9yE3/P1VRnQWj8A1FisYyTKW7ffZdZZtzu4W5GmbCVpZ0YYhllwvbve5llwlaWdsQ3Zj4dz/HHY4343wt78OsLe/DX71/i6Pvr+Cix233mKX7f0ZLa/+uZFnQOJcOwEQ+XX6JTNj4lAHzU9RJYbsRdcUcOnpACx4EQ3LI2lCjLfkQMNXwYsWn73AuqYU+aBPuoBXOyGyFVgn30V7jt0v7/Vye1P8KMdlwhdI2Kf/RWONwWzCXquBdUWEd1QecNwjWwBH/qWDOHapPDS7IrhKxHOx5A2G3H0qX0c7gXALvbePGSBlw4FXenz4lkx0SRFxRPSIFrAAi5dMdrG4Fh4Euyw6WcQjxRxx+VYJ9MX4w3P29OBMJHcEt3TvxRCXa3dt5S5+NSBEDEcO70Q3CbtpP1vGU9w5tqGzqH1ugU4hdOID5zE+s9pyH1A8A0VhZXgJ630aKr3/Trw2hevgn1yg1daX7O2bDwvtad++kR2JK/VwAR3Wsy/H68QUzAm97nCkHtcxiDxRuE4rYDC8n3igxZtmFkOl3FUFdxoCtRNzVsPzGYeJz4t2dkHXXBctV4LIbfz6hV91q051IX3Ns61Fo/QZh6U+i27m7jz1m2N97ILDNuh/B6RpmwlaWdbnRnlAlb76HMMmErSzv2YmbPduGvF5vxaeKnuw91b5nudfympxE3/5Lej1gzrn8PvH74RapaZ9dLINlzPJMux3JD+nH5jAdwqk9FyCNcnEugLvhTgaQueI0XgmztTI9gLgpY+/UfHlSEXOlg8/24pNuXZMWRjE/MhfN8aIekhuDXzR36hr2G0AYARP26C0gE8WKv+eMBnOoDIpdyXBRTVIRc6TqTixFAsmi98oLOmw8jNuOHgcnFfJfTLApox/OhHVLUX5Y51/XFKfyUDLXYOax8D7Qd1j6FbFy5imewYndq9OM42vra8ezLc9hIPUOBpF/hNzl7ZgWYGDSGyPR13Da8D5wIvGcV3ivZSLC7FSijXQi5Sp8DVBfc6fM/fQ+Gv443LZAQwa3U72cSt6KAZDGO71Rb/QQh1aiXODpmHBr9fU9yXyP+swy81vkSwAu81dGIxz0bcAN4vfMlHutDNZ83LZCwhHt5L9TlkrgY6HrQjj6xziYmBiFfihiGsjKHkQrw4F7W4C//RUNF/I5YJhLO/8Sg0Mvd/LxlDN+NlvI68rXjxKEDgBovMmCL0fELNAGpXmHbsSnt5/7TaO+I4L+L4gPy8w3bEj395OvJN1yZizjk7II9y2jw5udFRWghAkD4sFVOd+JQDR8SPTjSV8ixVVaBVyKiXBpxcyYxLKrf/rwL0Pcg+zfQGW3F9e9f4K3+l/ifDuDhUoFvvztxqOjCoaIvEKVQjUOEJfWi9cNI2nCfNWN4tXTbfdHIbpPz5g1mDr9eKuV15GvHh3sPKvFBQWf5h1SPb+Prb7HecRht3UDLYSvWFy/juVC9EKlh4RzD3/k5EQg7YI36defDjVCxIwNJX2gf4qQBV9ner9mkPyRqQ7Cl9j7LpcArEVEWsSb8c9k4Zyj6dKkR6HiFPx1+iX9+3QjXjRZ0Ht7Q5g8VsXYO0/ewZPiU6kEwY7FMGUxfx23VOPdVFhO38s6pZDO5GAH0cysAnLMTsEsRzJXzopF8zYm5upKUdN48CGbrEWb0GHQKaCcSV4G+I6nX4pwNl7xYxqDfh309K1i5oesWx85h5ft2tL//Odp7IlgpYm4wF98Xt7PMGWtD3sbh+dy094m+xIfr36iFh9vEYGLeu3wf3pKSQ9f6DzHbHYJgENLWNOIPF3fjJp7jj7qhUcPKUaURjzue4yia8YdYIjw7nuNoRyP+ExOeLqdJDLpCwIAr8SnyFOIu4VOvbkWca0BKLO4odqjJhxGbGyEkH5veirkgZAwBJj71puetdKvq3HZIuuG+1AKHLMOr2gKcct8fqS0y8keFhWhFrT4t4LxN+LUFSqkhwFOIX8qyUGh6BN7ERTj5HOlFH5u34xu2GV6LyzJXQs8zghfLQHP/ufSK0SHg0YXf4anwnn1+4ybWO9qBEnuDGStG3XYsZczX+jDi0RadZP5+fBi5qn1oSu5zWebgj+ofn+h1Cu+nfH8b2nnUem7J858+VmEVaxGL7ybtfkT0ryPj9WyPht7e3ldiYT6rq6tiERGROXVPYf/YYazNZIYkiZwIhF2wP/ALUw3aCM92DpGyR0hEVJJxSGNHgcWLDMGt8B6BFcDSj9sTgmCPkIioSN1T2D92FM3iLRa0ucR9nsZZW+OtOduBQUhERKbGoVEiIjI1BiEREZkag5CIiEyNQUhERKbGICQiIlNjEBIRkakxCImIyNSKDsLGxqIfQkREVLOKTrWGhgaxiIiIqG4VHYRNTdrXUhIREe0EDEIiIjK1ooOwoaGBYUhERDtG0UEIALt27RKLiIiI6lJJQdjU1MTVo0REtCOUnGbsFRIR0U6wpSBkGBIRUb0rOQgBoKWlhQtniIiorm0pCJEIQ84XEhFRvdpygjU0NKC1tZU9QyIiqktbDkLowpBzhkREVG/KEoRJLS0tHColIqK6UvbE2rVrF9ra2jhcSkREdaHsQZjU1NSE1tZW7N69O7W6lD1FIiKqNQ29vb2vxEIiIiKzYBeNiIhM7f8B2CwfwgMAaSkAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function  | Example               | Creates new dim? | Result rank |\n",
    "| --------- | --------------------- | ---------------- | ----------- |\n",
    "| `cat()`   | `cat((e,f), dim=0)`   | âŒ no             | stays same  |\n",
    "| `stack()` | `stack((e,f), dim=0)` | âœ” yes            | rank + 1    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked along new dim=1 (Shape: torch.Size([2, 2, 3])):\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 3,  4,  5],\n",
      "         [ 9, 10, 11]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack along a new dimension 1\n",
    "# Resulting shape: (2, 2, 3)\n",
    "\n",
    "stack_dim1 = torch.stack((tensor_e, tensor_f), dim=1)\n",
    "print(f\"Stacked along new dim=1 (Shape: {stack_dim1.shape}):\\n{stack_dim1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked along new dim=2 (Shape: torch.Size([2, 3, 2])):\n",
      "tensor([[[ 0,  6],\n",
      "         [ 1,  7],\n",
      "         [ 2,  8]],\n",
      "\n",
      "        [[ 3,  9],\n",
      "         [ 4, 10],\n",
      "         [ 5, 11]]])\n"
     ]
    }
   ],
   "source": [
    "# Stack along a new dimension 2 (last dimension)\n",
    "# Resulting shape: (2, 3, 2)\n",
    "stack_dim2 = torch.stack((tensor_e, tensor_f), dim=2)\n",
    "print(f\"Stacked along new dim=2 (Shape: {stack_dim2.shape}):\\n{stack_dim2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding `dim=2`:\n",
    "\n",
    "dim 0 -> rows\n",
    "dim 1 -> columns\n",
    "\n",
    "when you do `dim=2`, it's saying like -->\n",
    "\" create a New demension after the existing 2 dimensions.\"\n",
    "\n",
    "so the new shape becomes:\n",
    "(2, 3, 2)\n",
    "\n",
    "Think of this rule:\n",
    "When stacking at dim=2, each element of E is paired with the corresponding element of F.\n",
    "E[i, j] pairs with F[i, j]\n",
    "\n",
    "Row 0:\n",
    "E: 0 1 2\n",
    "F: 6 7 8\n",
    "\n",
    "Pairs become:\n",
    "[0, 6]\n",
    "[1, 7]\n",
    "[2, 8]\n",
    "\n",
    "Row 1:\n",
    "E: 3 4 5\n",
    "F: 9 10 11\n",
    "\n",
    "Pairs become:\n",
    "[3, 9]\n",
    "[4, 10]\n",
    "[5, 11]\n",
    "\n",
    "[\n",
    "  [ [0, 6],\n",
    "    [1, 7],\n",
    "    [2, 8] ],\n",
    "\n",
    "  [ [3, 9],\n",
    "    [4, 10],\n",
    "    [5, 11] ]\n",
    "]\n",
    "\n",
    "Interpretation:\n",
    "* 2 rows\n",
    "* 3 columns\n",
    "* each cell now has 2 values (one from E, one from F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (Shape: torch.Size([6, 2])):\n",
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting into Specific Sizes with torch.split \n",
    "# The torch.split function divides a tensor into chunks along a specified dimension.\n",
    "\n",
    "import torch\n",
    "# Create a tensor to split\n",
    "tensor_g = torch.arange(12).reshape(6, 2)\n",
    "print(f\"Original Tensor (Shape: {tensor_g.shape}):\\n{tensor_g}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into equal chunks of size 2 (dim=0):\n",
      " Chunk 0 (Shape: torch.Size([2, 2])):\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      " Chunk 1 (Shape: torch.Size([2, 2])):\n",
      "tensor([[4, 5],\n",
      "        [6, 7]])\n",
      " Chunk 2 (Shape: torch.Size([2, 2])):\n",
      "tensor([[ 8,  9],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks of size 2 along dimension 0 (rows)\n",
    "# 6 rows / 2 rows/chunk = 3 chunks\n",
    "split_equal = torch.split(tensor_g, 2, dim=0)\n",
    "print(\"Split into equal chunks of size 2 (dim=0):\")\n",
    "for i, chunk in enumerate(split_equal):\n",
    "    print(f\" Chunk {i} (Shape: {chunk.shape}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split into unequal chunks [1, 2, 3] (dim=0):\n",
      " Chunk 0 (Shape: torch.Size([1, 2])):\n",
      "tensor([[0, 1]])\n",
      " Chunk 1 (Shape: torch.Size([2, 2])):\n",
      "tensor([[2, 3],\n",
      "        [4, 5]])\n",
      " Chunk 2 (Shape: torch.Size([3, 2])):\n",
      "tensor([[ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks of sizes [1, 2, 3] along dimension 0\n",
    "# Total size must sum to the dimension size (1 + 2 + 3 = 6)\n",
    "split_unequal = torch.split(tensor_g, [1, 2, 3], dim=0)\n",
    "print(\"\\nSplit into unequal chunks [1, 2, 3] (dim=0):\")\n",
    "for i, chunk in enumerate(split_unequal):\n",
    "    print(f\" Chunk {i} (Shape: {chunk.shape}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split into equal chunks of size 1 (dim=1):\n",
      " Chunk 0 (Shape: torch.Size([6, 1])):\n",
      "tensor([ 0,  2,  4,  6,  8, 10])\n",
      " Chunk 1 (Shape: torch.Size([6, 1])):\n",
      "tensor([ 1,  3,  5,  7,  9, 11])\n"
     ]
    }
   ],
   "source": [
    "# Split along dimension 1 (columns)\n",
    "# Shape: (6, 2). Split into chunks of size 1 along dim=1\n",
    "split_dim1 = torch.split(tensor_g, 1, dim=1)\n",
    "print(\"\\nSplit into equal chunks of size 1 (dim=1):\")\n",
    "for i, chunk in enumerate(split_dim1):\n",
    "    # Using squeeze removes the dimension of size 1 for clearer display\n",
    "    print(f\" Chunk {i} (Shape: {chunk.shape}):\\n{chunk.squeeze()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (Shape: torch.Size([5, 2])):\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting into a Number of Chunks with torch.chunk \n",
    "# torch.chunk splits a tensor into a specified number of chunks along a given dimension.\n",
    "\n",
    "# Create a tensor\n",
    "tensor_h = torch.arange(10).reshape(5, 2) # Size 5 along dim 0\n",
    "print(f\"Original Tensor (Shape: {tensor_h.shape}):\\n{tensor_h}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked into 3 parts (dim=0):\n",
      " Chunk 0 (Shape: torch.Size([2, 2])):\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      " Chunk 1 (Shape: torch.Size([2, 2])):\n",
      "tensor([[4, 5],\n",
      "        [6, 7]])\n",
      " Chunk 2 (Shape: torch.Size([1, 2])):\n",
      "tensor([[8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Split into 3 chunks along dimension 0\n",
    "# 5 rows / 3 chunks -> sizes will be [2, 2, 1] ( ceil(5/3)=2 for first chunks)\n",
    "chunked_tensor = torch.chunk(tensor_h, 3, dim=0)\n",
    "print(\"Chunked into 3 parts (dim=0):\")\n",
    "for i, chunk in enumerate(chunked_tensor):\n",
    "    print(f\" Chunk {i} (Shape: {chunk.shape}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Tensor (Shape: torch.Size([3, 4])):\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create another tensor\n",
    "tensor_i = torch.arange(12).reshape(3, 4) # Size 4 along dim 1\n",
    "print(f\"\\nOriginal Tensor (Shape: {tensor_i.shape}):\\n{tensor_i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked into 2 parts (dim=1):\n",
      " Chunk 0 (Shape: torch.Size([3, 2])):\n",
      "tensor([[0, 1],\n",
      "        [4, 5],\n",
      "        [8, 9]])\n",
      " Chunk 1 (Shape: torch.Size([3, 2])):\n",
      "tensor([[ 2,  3],\n",
      "        [ 6,  7],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Split into 2 chunks along dimension 1\n",
    "# 4 cols / 2 chunks -> sizes will be [2, 2] ( ceil(4/2)=2 )\n",
    "chunked_tensor_dim1 = torch.chunk(tensor_i, 2, dim=1)\n",
    "print(\"Chunked into 2 parts (dim=1):\")\n",
    "for i, chunk in enumerate(chunked_tensor_dim1):\n",
    "    print(f\" Chunk {i} (Shape: {chunk.shape}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.chunk` is convenient when you know how many pieces you want, regardless of whether the dimension size divides evenly. `torch.split` gives you more control when you need chunks of exact, potentially varying, sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor A: Shape [2, 3]\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "# Scalar B: Shape [] (0 dimensions)\n",
    "b = torch.tensor(10)\n",
    "\n",
    "# Add scalar to tensor\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([2, 3])\n",
      "Shape of b: torch.Size([])\n",
      "Shape of c: torch.Size([2, 3])\n",
      "Result c:\n",
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of a: {a.shape}\")\n",
    "# Shape of a: torch.Size([2, 3])\n",
    "print(f\"Shape of b: {b.shape}\")\n",
    "# Shape of b: torch.Size([])\n",
    "print(f\"Shape of c: {c.shape}\")\n",
    "# Shape of c: torch.Size([2, 3])\n",
    "print(f\"Result c:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([2, 3])\n",
      "Shape of b: torch.Size([3])\n",
      "Shape of c: torch.Size([2, 3])\n",
      "Result c:\n",
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor A: Shape [2, 3]\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "# Tensor B: Shape [3] (can be seen as [1, 3] for broadcasting)\n",
    "b = torch.tensor([10, 20, 30])\n",
    "\n",
    "# Add row vector to matrix\n",
    "c = a + b\n",
    "\n",
    "print(f\"Shape of a: {a.shape}\") # torch.Size([2, 3])\n",
    "print(f\"Shape of b: {b.shape}\") # torch.Size([3])\n",
    "print(f\"Shape of c: {c.shape}\") # torch.Size([2, 3])\n",
    "print(f\"Result c:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([2, 3])\n",
      "Shape of b: torch.Size([2, 1])\n",
      "Shape of c: torch.Size([2, 3])\n",
      "Result c:\n",
      "tensor([[11, 12, 13],\n",
      "        [24, 25, 26]])\n"
     ]
    }
   ],
   "source": [
    "# Column Vector and Matrix\n",
    "# Tensor A: Shape [2, 3]\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "# Tensor B: Shape [2, 1]\n",
    "b = torch.tensor([[10], [20]])\n",
    "\n",
    "# Add column vector to matrix\n",
    "c = a + b\n",
    "\n",
    "print(f\"Shape of a: {a.shape}\") # torch.Size([2, 3])\n",
    "print(f\"Shape of b: {b.shape}\") # torch.Size([2, 1])\n",
    "print(f\"Shape of c: {c.shape}\") # torch.Size([2, 3])\n",
    "print(f\"Result c:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incompatible Shapes\n",
    "# Broadcasting fails if the non-matching dimensions are not 1.\n",
    "\n",
    "# Tensor A: Shape [2, 3]\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "# Tensor B: Shape [2]\n",
    "b = torch.tensor([10, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    c = a + b\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trailing dimension: a has 3, b has 2. Neither is 1. Incompatible. The operation fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1.1000, 2.2000, 3.3000]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Type Casting\n",
    "# convert tensors from one data type to another. This is known as type casting. \n",
    "# primary way to cast a tensor is using the .to()\n",
    "\n",
    "float_tensor = torch.tensor([1.1, 2.2, 3.3], dtype=torch.float32)\n",
    "print(f\"Original tensor: {float_tensor}, dtype: {float_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casted to int64: tensor([1, 2, 3]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Cast to int64 using .to()\n",
    "int_tensor = float_tensor.to(torch.int64)\n",
    "print(f\"Casted to int64: {int_tensor}, dtype: {int_tensor.dtype}\") # Note the truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casted to float16: tensor([1., 2., 3.], dtype=torch.float16), dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Cast back to float16 using .to()\n",
    "half_tensor = int_tensor.to(dtype=torch.float16) # Can specify only dtype\n",
    "print(f\"Casted to float16: {half_tensor}, dtype: {half_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".float(): tensor([0., 1., 0., 1.]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.tensor([0, 1, 0, 1])\n",
    "\n",
    "# Cast to float using .float()\n",
    "tensor_b = tensor_a.float() # Equivalent to .to(torch.float32)\n",
    "print(f\"\\n.float(): {tensor_b}, dtype: {tensor_b.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".long(): tensor([0, 1, 0, 1]), dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Cast to long using .long()\n",
    "tensor_c = tensor_b.long() # Equivalent to .to(torch.int64)\n",
    "print(f\".long(): {tensor_c}, dtype: {tensor_c.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bool(): tensor([False,  True, False,  True]), dtype: torch.bool\n"
     ]
    }
   ],
   "source": [
    "# Cast to bool using .bool()\n",
    "tensor_d = tensor_a.bool() # Equivalent to .to(torch.bool)\n",
    "print(f\".bool(): {tensor_d}, dtype: {tensor_d.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "casting usually creates a new tensor in memory with the specified data type, rather than modifying the original tensor in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "int32 + float32 = tensor([1.5000, 2.5000]), dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "int_t = torch.tensor([1, 2], dtype=torch.int32)\n",
    "float_t = torch.tensor([0.5, 0.5], dtype=torch.float32)\n",
    "double_t = torch.tensor([0.1, 0.1], dtype=torch.float64)\n",
    "\n",
    "# int32 + float32 -> float32\n",
    "result1 = int_t + float_t\n",
    "print(f\"\\nint32 + float32 = {result1}, dtype: {result1.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 + float64 = tensor([0.6000, 0.6000], dtype=torch.float64), dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# float32 + float64 -> float64\n",
    "result2 = float_t + double_t\n",
    "print(f\"float32 + float64 = {result2}, dtype: {result2.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
