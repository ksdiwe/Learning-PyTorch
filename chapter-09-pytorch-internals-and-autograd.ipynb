{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e06d728",
   "metadata": {},
   "source": [
    "# PyTorch Internals and Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d083b2d",
   "metadata": {},
   "source": [
    "### Tensor Implementation Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8cee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor x: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n",
      "Storage elements: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0]\n",
      "Storage type: torch.float32\n",
      "Storage size: 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print(f\"Original tensor x: {x}\")\n",
    "\n",
    "# Storage is a 1D array of 12 floats\n",
    "print(f\"Storage elements: {x.storage().tolist()}\")\n",
    "print(f\"Storage type: {x.storage().dtype}\")\n",
    "print(f\"Storage size: {len(x.storage())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e604243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage elements: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0]\n",
      "Number of elements: 12\n",
      "Tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Storage is a 1D array of 12 floats\n",
    "print(f\"Storage elements: {x.reshape(-1).tolist()}\")\n",
    "print(f\"Number of elements: {x.numel()}\")\n",
    "print(f\"Tensor dtype: {x.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12b2223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reshaped tensor y:\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Does y share storage with x? True\n",
      "\n",
      "Modified y:\n",
      "tensor([[99.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Original x after modifying y: tensor([99.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    }
   ],
   "source": [
    "# Create a view by reshaping\n",
    "y = x.view(3, 4)\n",
    "print(f\"\\nReshaped tensor y:\\n{y}\")\n",
    "\n",
    "# y has different shape/strides but shares the same storage\n",
    "print(f\"Does y share storage with x? {y.storage().data_ptr() == x.storage().data_ptr()}\")\n",
    "\n",
    "# Modifying the view affects the original (and vice versa)\n",
    "y[0, 0] = 99.0\n",
    "print(f\"\\nModified y:\\n{y}\")\n",
    "print(f\"Original x after modifying y: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a86ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t:\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Shape: torch.Size([3, 4])\n",
      "Stride: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# Tensor Metadata\n",
    "import torch\n",
    "\n",
    "t = torch.arange(12, dtype=torch.float32).view(3, 4) # view() requires the tensor to be contiguous\n",
    "print(f\"Tensor t:\\n{t}\")\n",
    "print(f\"Shape: {t.shape}\")\n",
    "print(f\"Stride: {t.stride()}\") \n",
    "\n",
    "# Stride: It's a tuple where the i-th element specifies the jump in memory \n",
    "# (number of elements in the storage) needed to move one step along the i-th dimension of the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb309a0",
   "metadata": {},
   "source": [
    "The stride (4, 1) means:\n",
    "\n",
    "* To move one step along dimension 0 (down a row), you need to jump 4 elements in the underlying 1D `Storage`. (e.g., from element 0 to element 4).\n",
    "* To move one step along dimension 1 (across a column), you need to jump 1 element in the underlying 1D `Storage`. (e.g., from element 0 to element 1).\n",
    "\n",
    "The stride determines how the multi-dimensional tensor maps onto the linear `Storage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6628e95b",
   "metadata": {},
   "source": [
    "Having some better understanding of `Stride`:\n",
    "\n",
    "`Stride: (4, 1)` means:\n",
    "* Moving 1 step in dim 0 (row direction) --> jump 4 elements in memory\n",
    "* Moving 1 step in dim 1 (column direction) --> jump 1 element in memory\n",
    "\n",
    "Why 4?\n",
    "because each row has 4 columns --> to go from row0 --> row1 --> skip 4 elements\n",
    "\n",
    "Why 1?\n",
    "because elements in the same row are adjacent in memory.\n",
    "\n",
    "Memory in 1D: [ a, b, c, d, e, f, g, h, i, j, k, l]\n",
    "tensor shape: 3 rows x 4 columns\n",
    "\n",
    "Stride `(4, 1)` means:\n",
    "* row step = +4 in memory\n",
    "* col step = +1 in memory\n",
    "\n",
    "so,\n",
    "* x[0][0] = a\n",
    "* x[1][0] = a + 4 steps = e\n",
    "* x[0][1] = a + 1 step = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212aa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is t contiguous? {t.is_contiguous()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
