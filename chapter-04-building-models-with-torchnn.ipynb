{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d314bd84",
   "metadata": {},
   "source": [
    "# Building Models with `torch.nn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bca90",
   "metadata": {},
   "source": [
    "## The `torch.nn.Module` Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f67c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNetwork(\n",
      "  (layer1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# skeleton of a custom module:\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetwork, self).__init__()\n",
    "        # define layers or components here\n",
    "        # example: a linear layer\n",
    "        self.layer1 = nn.Linear(in_features=10, out_features=5)\n",
    "        # example: an activation function instance\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define the flow of data through the components\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "# Instantiate the network\n",
    "model = SimpleNetwork()\n",
    "print(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d50df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: my_weight, Shape: torch.Size([5, 2]), Requires grad: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModuleWithParameter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A learnable parameter tensor\n",
    "        self.my_weight = nn.Parameter(torch.randn(5, 2))\n",
    "        # A regular tensor attribute (not automatically tracked for optimization)\n",
    "        self.my_info = torch.tensor([1.0, 2.0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Example usage\n",
    "        return torch.matmul(x, self.my_weight)\n",
    "\n",
    "module = CustomModuleWithParameter()\n",
    "\n",
    "# Accessing parameters tracked by the module\n",
    "for name, param in module.named_parameters():\n",
    "    print(f\"Parameter name: {name}, Shape: {param.shape}, Requires grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0eac62",
   "metadata": {},
   "source": [
    "## Defining Custom Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac68380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized SimpleLinearModel with input_features=10, output_features=1\n",
      "Layer defined: Linear(in_features=10, out_features=1, bias=True)\n",
      "\n",
      "Dummy input tensor shape: torch.Size([5, 10])\n",
      "Forward pass input shape: torch.Size([5, 10])\n",
      "Forward pass output shape: torch.Size([5, 1])\n",
      "Model output tensor shape: torch.Size([5, 1])\n",
      "\n",
      "Model Parameters:\n",
      "Name: linear_layer.weight, Shape: torch.Size([1, 10])\n",
      "Name: linear_layer.bias, Shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# a simple linear regression model implemented as a custom module\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        # call the parent class constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        # defining the single linear layer\n",
    "        self.linear_layer = nn.Linear(input_features, output_features)\n",
    "        print(f\"Initialized SimpleLinearModel with input_features={input_features}, output_features={output_features}\")\n",
    "        print(f\"Layer defined: {self.linear_layer}\")\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define the forward pass: pass input through the linear layer\n",
    "        print(f\"Forward pass input shape: {x.shape}\")\n",
    "        output = self.linear_layer(x)\n",
    "        \n",
    "        print(f\"Forward pass output shape: {output.shape}\")\n",
    "        return output\n",
    "    \n",
    "# define input and output dimensions\n",
    "in_dim = 10\n",
    "out_dim = 1\n",
    "\n",
    "# Instantiate the custom model\n",
    "model = SimpleLinearModel(input_features=in_dim, output_features=out_dim)\n",
    "\n",
    "# create some dummy input data (batch_size=5, features=10)\n",
    "dummy_input = torch.randn(5, in_dim)\n",
    "print(f\"\\nDummy input tensor shape: {dummy_input.shape}\")\n",
    "\n",
    "# pass the data through the model\n",
    "output = model(dummy_input)\n",
    "print(f\"Model output tensor shape: {output.shape}\")\n",
    "\n",
    "# Inspect parameters (automatically registered)\n",
    "print(\"\\nModel Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Name: {name}, Shape: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa6517",
   "metadata": {},
   "source": [
    "#### `Building a Multi-Layer Perceptron (MLP)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52effc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized SimpleMLP: Input=784, Hidden=128, Output=10\n",
      "Layer 1: Linear(in_features=784, out_features=128, bias=True)\n",
      "Activation: ReLU()\n",
      "Layer 2: Linear(in_features=128, out_features=10, bias=True)\n",
      "\n",
      "Dummy MLP input shape: torch.Size([32, 784])\n",
      "Forward pass input shape: torch.Size([32, 784])\n",
      "After layer 1 shape: torch.Size([32, 128])\n",
      "After activation shape: torch.Size([32, 128])\n",
      "After layer 2 (output) shape: torch.Size([32, 10])\n",
      "MLP output shape: torch.Size([32, 10])\n",
      "\n",
      "MLP Model Parameters:\n",
      "  Name: layer1.weight, Shape: torch.Size([128, 784])\n",
      "  Name: layer1.bias, Shape: torch.Size([128])\n",
      "  Name: layer2.weight, Shape: torch.Size([10, 128])\n",
      "  Name: layer2.bias, Shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # Often used for functional APIs like activation functions\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        # Define layers\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU() # Define activation as a layer\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        print(f\"Initialized SimpleMLP: Input={input_size}, Hidden={hidden_size}, Output={output_size}\")\n",
    "        print(f\"Layer 1: {self.layer1}\")\n",
    "        print(f\"Activation: {self.activation}\")\n",
    "        print(f\"Layer 2: {self.layer2}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass sequence\n",
    "        print(f\"Forward pass input shape: {x.shape}\")\n",
    "        x = self.layer1(x)\n",
    "        print(f\"After layer 1 shape: {x.shape}\")\n",
    "        x = self.activation(x) # Apply ReLU activation\n",
    "        \n",
    "        print(f\"After activation shape: {x.shape}\")\n",
    "        x = self.layer2(x)\n",
    "        print(f\"After layer 2 (output) shape: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "# --- Usage Example ---\n",
    "# Define dimensions\n",
    "in_size = 784 # Example: Flattened 28x28 image\n",
    "hidden_units = 128\n",
    "out_size = 10   # Example: 10 classes for classification\n",
    "\n",
    "# Instantiate the MLP\n",
    "mlp_model = SimpleMLP(input_size=in_size, hidden_size=hidden_units, output_size=out_size)\n",
    "\n",
    "# Create dummy input (batch_size=32)\n",
    "dummy_mlp_input = torch.randn(32, in_size)\n",
    "print(f\"\\nDummy MLP input shape: {dummy_mlp_input.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "mlp_output = mlp_model(dummy_mlp_input)\n",
    "print(f\"MLP output shape: {mlp_output.shape}\")\n",
    "\n",
    "# Inspect parameters\n",
    "print(\"\\nMLP Model Parameters:\")\n",
    "for name, param in mlp_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  Name: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5497ea2",
   "metadata": {},
   "source": [
    "## Comman Layers: Linear, Convolutional, Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe5080",
   "metadata": {},
   "source": [
    "#### Linear Layers (nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6618565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 20])\n",
      "Output shape: torch.Size([64, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example: Expecting input features of size 20, producing output features of size 30\n",
    "linear_layer = nn.Linear(in_features=20, out_features=30)\n",
    "\n",
    "# Create a sample input tensor (batch size 64, 20 features)\n",
    "input_tensor = torch.randn(64, 20)\n",
    "\n",
    "# Pass the input through the layer\n",
    "output_tensor = linear_layer(input_tensor)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f55aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight shape: torch.Size([30, 20])\n",
      "Bias shape: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the layer's parameters (automatically created)\n",
    "print(f\"\\nWeight shape: {linear_layer.weight.shape}\")\n",
    "print(f\"Bias shape: {linear_layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f853e",
   "metadata": {},
   "source": [
    "#### Convolutional Layers (nn.Conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e60c7",
   "metadata": {},
   "source": [
    "Important parameters for `nn.Conv2d` include:\n",
    "\n",
    "* `in_channels`: Number of channels in the input image (e.g., 3 for RGB images).\n",
    "* `out_channels`: Number of filters to apply. Each filter produces one output channel (feature map).\n",
    "* `kernel_size`: The dimensions (height, width) of the filters. Can be a single int for square kernels or a tuple (H, W).\n",
    "* `stride` (optional, default 1): How many pixels the filter moves at each step.\n",
    "* `padding` (optional, default 0): Amount of zero-padding added to the input borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e10020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process a batch of 16 images, 3 channels (RGB), 32x32 pixels\n",
    "# Apply 6 filters (output channels), each 5x5 in size\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbb153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input tensor (batch_size, channels, height, width)\n",
    "# PyTorch typically expects channels-first format (N, C, H, W)\n",
    "input_image_batch = torch.randn(16, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c55863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 3, 32, 32])\n",
      "Output shape: torch.Size([16, 6, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Pass the input through the convolutional layer\n",
    "output_feature_maps = conv_layer(input_image_batch)\n",
    "\n",
    "print(f\"Input shape: {input_image_batch.shape}\")\n",
    "print(f\"Output shape: {output_feature_maps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1559ab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight (filter) shape: torch.Size([6, 3, 5, 5])\n",
      "Bias shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Inspect parameters\n",
    "print(f\"\\nWeight (filter) shape: {conv_layer.weight.shape}\") \n",
    "print(f\"Bias shape: {conv_layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd29fe9",
   "metadata": {},
   "source": [
    "#### Recurrent Layers (nn.RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a996aad",
   "metadata": {},
   "source": [
    "Important parameters for `nn.RNN`:\n",
    "\n",
    "* `input_size`: The number of features in the input at each time step.\n",
    "* `hidden_size`: The number of features in the hidden state.\n",
    "* `num_layers` (optional, default 1): Number of stacked RNN layers.\n",
    "* `batch_first` (optional, default False): If True, input and output tensors are provided as `(batch, seq_len, features)` instead of the default `(seq_len, batch, features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ea1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process a batch of 10 sequences, each 20 steps long, with 5 features per step.\n",
    "# Use a hidden state size of 30.\n",
    "# Set batch_first=True for easier data handling.\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=30, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54018c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input tensor (batch, seq_len, input_features)\n",
    "input_sequence_batch = torch.randn(10, 20, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981117e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the hidden state (num_layers, batch, hidden_size)\n",
    "# If not provided, it defaults to zeros.\n",
    "initial_hidden_state = torch.randn(1, 10, 30) # num_layers=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1bce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input sequence and initial hidden state through the RNN\n",
    "# Output contains outputs for all time steps\n",
    "# Final_hidden_state contains the hidden state for the last time step\n",
    "output_sequence, final_hidden_state = rnn_layer(input_sequence_batch, initial_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329e89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([10, 20, 5])\n",
      "Initial hidden state shape: torch.Size([1, 10, 30])\n",
      "Output sequence shape: torch.Size([10, 20, 30])\n",
      "Final hidden state shape: torch.Size([1, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {input_sequence_batch.shape}\")\n",
    "print(f\"Initial hidden state shape: {initial_hidden_state.shape}\")\n",
    "print(f\"Output sequence shape: {output_sequence.shape}\") # (batch, seq_len, hidden_size)\n",
    "print(f\"Final hidden state shape: {final_hidden_state.shape}\") # (num_layers, batch, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d10ab",
   "metadata": {},
   "source": [
    "## Activation Functions (ReLU, Sigmoid, Tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3b2f1",
   "metadata": {},
   "source": [
    "#### ReLU (Rectified Linear Unit)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c324e310",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360ab870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 0.2275,  0.5938, -0.2248,  0.9974])\n",
      "Output after ReLU: tensor([0.2275, 0.5938, 0.0000, 0.9974])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "relu_activation = nn.ReLU()\n",
    "input_tensor = torch.randn(4)\n",
    "output_tensor = relu_activation(input_tensor)\n",
    "\n",
    "print(f\"Input: {input_tensor}\")\n",
    "print(f\"Output after ReLU: {output_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9659438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 20)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x) # Apply ReLU\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1b78c",
   "metadata": {},
   "source": [
    "`The ReLU function is zero for negative inputs and linear for positive inputs.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05acd0a1",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d7cf7ee3",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b62daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([-0.6983,  1.3524,  0.6727, -1.1562])\n",
      "Output after Sigmoid: tensor([0.3322, 0.7945, 0.6621, 0.2394])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example usage\n",
    "sigmoid_activation = nn.Sigmoid()\n",
    "input_tensor = torch.randn(4) # Example input tensor\n",
    "output_tensor = sigmoid_activation(input_tensor)\n",
    "\n",
    "print(f\"Input: {input_tensor}\")\n",
    "print(f\"Output after Sigmoid: {output_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf11ffd",
   "metadata": {},
   "source": [
    "`The Sigmoid function smoothly maps any real number to the range (0, 1).`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe11f75",
   "metadata": {},
   "source": [
    "#### Tanh (Hyperbolic Tangent)\n",
    "The hyperbolic tangent, or Tanh function, is mathematically related to Sigmoid but squashes its input into the range (-1, 1)."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d0e036b8",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7507a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([-0.3359, -0.8207,  0.9045, -0.8094])\n",
      "Output after Tanh: tensor([-0.3238, -0.6755,  0.7185, -0.6693])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example usage\n",
    "tanh_activation = nn.Tanh()\n",
    "input_tensor = torch.randn(4) # Example input tensor\n",
    "output_tensor = tanh_activation(input_tensor)\n",
    "\n",
    "print(f\"Input: {input_tensor}\")\n",
    "print(f\"Output after Tanh: {output_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74009479",
   "metadata": {},
   "source": [
    "`The tanh function smoothly maps any real number to the range (-1, 1).`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a008194",
   "metadata": {},
   "source": [
    "## Sequential Containers for Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71c5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple two-layer feed-forward network\n",
    "# 784-dimensional input, 128 units hidden layer, ReLU activation, 10-dimensional output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define input, hidden, and output dimensions\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72302824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model V1 (Unnamed Layers):\n",
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Passing modules directly as arguments\n",
    "model_v1 = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size), # Layer 1: Linear transformation\n",
    "    nn.ReLU(),                         # Activation 1: Non-linearity\n",
    "    nn.Linear(hidden_size, output_size) # Layer 2: Linear transformation\n",
    ")\n",
    "\n",
    "# Print the model structure\n",
    "print(\"Model V1 (Unnamed Layers):\")\n",
    "print(model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ffea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Assume a batch size of 64\n",
    "dummy_input = torch.randn(64, input_size)\n",
    "output = model_v1(dummy_input)\n",
    "print(\"\\nOutput shape:\", output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d4f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model V2 (Named Layers):\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Using an OrderedDict for named layers\n",
    "model_v2 = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_size)), # Fully connected layer 1\n",
    "    ('relu1', nn.ReLU()),                      # ReLU activation\n",
    "    ('fc2', nn.Linear(hidden_size, output_size)) # Fully connected layer 2\n",
    "]))\n",
    "\n",
    "# Print the model structure\n",
    "print(\"\\nModel V2 (Named Layers):\")\n",
    "print(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2ac13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accessing fc1 weights shape: torch.Size([128, 784])\n",
      "Accessing layer at index 0: Linear(in_features=784, out_features=128, bias=True)\n",
      "Accessing layer by name 'relu1': ReLU()\n"
     ]
    }
   ],
   "source": [
    "# Accessing a specific layer by name is now possible\n",
    "print(\"\\nAccessing fc1 weights shape:\", model_v2.fc1.weight.shape)\n",
    "# You can also access using integer indices if needed\n",
    "print(\"Accessing layer at index 0:\", model_v2[0])\n",
    "# Or by the string name directly if using OrderedDict\n",
    "print(\"Accessing layer by name 'relu1':\", model_v2.relu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9868ba",
   "metadata": {},
   "source": [
    "## Loss Functions (`torch.nn` losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d778f9f",
   "metadata": {},
   "source": [
    "The core idea is simple: a loss function takes the model's output (predictions) and the ground truth (targets) as input, and computes a single scalar value representing the \"error\" or \"loss\". \n",
    "\n",
    "This scalar loss value is then used by PyTorch's Autograd system during backpropagation to calculate gradients, which in turn guide the optimizer (like SGD or Adam from torch.optim) on how to adjust the model's parameters (weights and biases) to minimize this loss.\n",
    "\n",
    "`The loss function compares model predictions with target data to produce a scalar loss value, which guides parameter updates via backpropagation.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3978e",
   "metadata": {},
   "source": [
    "### Regression Losses"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ccbf0f4b",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSELoss)\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584fb42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.8289179801940918\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Instantiate the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Example predictions and targets (batch size 3, 1 output feature)\n",
    "predictions = torch.randn(3, 1, requires_grad=True)\n",
    "targets = torch.randn(3, 1)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = loss_fn(predictions, targets)\n",
    "print(f\"MSE Loss: {loss.item()}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAABICAYAAAAknEq1AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABBkSURBVHhe7d1xbBvXfcDxb2tQq3ddRsMIm+wUx5xjKls4O3RUM27kxCPiyFkmZ5U6gW6jGIJSQU40BZw0c2wEOjaUEnQdqBXk2WAtqI6gWjAiDSmbznI0xk21ZvIcs9EYGKJjMPPMxGGrkl1wSEfC2f4gJdEnmaJikpKp9wHuD773eKZ4z79793vvjl+4++67/w9BEIQC+KK6QBAEIV9EwBEEoWBEwBEEoWBEwBEEoWBEwBEEoWBEwBEEoWBEwBEEoWBEwBEEoWC+IBb+CflmanSzp1yH9AclXDmzF3tvGIBqh4cd6yQ0nymE3z5Ee29Q/VahyKzQarUvqgsFIZeuvjNC6E+/ivGPVlFaupr3X3+bq8CFUR86s5EL7Ta6zk6q3yYUIXFJJRSAhEkbZ/i1CZTVRqoemyq3IMcn8CrXtxaKlwg4QgFUUrYihPe0l8CkRNkjViSAh42UxPyIeLN8iIAj5N/DZcSv+AA/A++E0aw3Y10D8r0aFH9A3VooYiLgCHlnNEko/5lMFIdP+AgoMuYaM5a7S5h4S91aKGYi4Ah5lszfBN9OvVS8eMdjaDfUYY5PMKxqLRQ3EXCWPS2mWgfdx93UqatyIpW/SSvxD44RlnQg8jfLjgg4y5aVjuP99B8/SMvjJnQr1fU3z7TbSeeRGgzrttLZXDlTcXmAsYsRwiJ/s+yIhX8CdQdPUrU2hLfWTp+6UhBySIxwBEEoGBFwBEEoGBFwBEEoGBFwBEEoGJE0Fm4qaWxu89C6WTtT8GmCRHqD+ZRo0KxQF4Iy3kN9h1ilU2xEwBFuKuAgWXB0NmFKxRzFf5Rml29h62skGeP9mzA/ZMFsktGuABJBhhrbGVjQjoSlTlxSCTdH8dH1Yz+x1EvJ1IDzKVnVaB5KmMC/eek5aKNxVyNdZ8IkNAYqvmVQtxRuccsq4Bh2NlB9n7o0/3R/00DDZkldXDSUMy4OjURSrzToH2+hbr2qUdZijP6TjeeO+SnZbCVtuaBKBdZak7qweDxsxVquLrz15TjgaNFvMGKctelJu8pfFIbdbtq2xAm8p67JLe1DFsyq2BJ5I4SuvpPWbUsp6EytNO6nai2Anqr+fvqPd9OyRd12fkFPF94PUtkbjZ6qv2viZsYnsdMuXgnq2Fp7o+9Mj6ncqC5c0qT7LFRkG4j1JkyLcHLMtxzncCppcVmQJR36OyRIxAhfjhInjM/RtXg36q1voru9FN+z7QzlMSdg2OmkbZcR7Sd+ehwuhtMfYlfeQneTluHnDxTvA6fW1OF2VaHXJF/Gzh3FdnCB+Zys1eE+CPa9C846LQppcxMdz1mQCTF88AA9783zrex248aO/bi64taW4xHOMF0OO/ZXg8lOFv4FNocd+2IGG2Tqvr2Vkl8N5j/Y7CzB56ylfUTC2uGkKv1sdq6H0Y/LqH6uIq2wyFzu48APZ27I1JZbaVlSo7rFIW1uoqPRSKi3nvreMCZbB01FfImdSY4DzhJUbmXr2ijnB/3qmpwKX/XR83w7AxcheLKd5l4fkQ/TWygM/HKCko07sBZxX1POdNF3biqFrMX0bQfVRfz3ZkOJBhh0N9N1RkE500Wze5BANI9nvyWs6AOO8SE92l8HGb2srskt5ewoY2l9SP0agNcDhNBj3KEqLyoKvoNHGP116qXGQM2+upvK59zyLo4yejHD62Vk8QOOZKbB5aH3SCduVyee4x7c9ebkM28BMFC1txNPVydul5vOIx56p5/dkqkOQMJ8l45EJMSsByGst+I83Ev/8V46m9Muc9ZU4/Rknzg11DrpPtZPf28nLQ/PlMs1TjxdLZjTGzPGlUkNssFyXWnx8dP1fS+hqRzy2h3sqc9/yFnYsSiAHPWxYrLIAcdEy8FWKhJebHts2B02Gv/eR+LRFjoaU1OeNU9jNUQYaLFhd9ixtXkJfZZ6e6a61P51WojGQumFyX/3WRPh79czeKUE+f6tTHUH6S/NGLWQVaazvIU95WG6nhkkVCJjenB6L1jMRrQr1LsJoyggrcq8TkWuacXtcme9tdZk3t+iuNhHz+lQatWxBvnxNlrTgkDOLfhY5FuO+liRWdSAIz/zNBW3KwR93umFY0wO4AvEkR99moY1wJc1aG7TU1FrRpaSj6gceydMhHnqANCjvQ2UmGp88+gODJM+ei5WYSzVkPg4xFSGp9JQCp9GCI1f/5a5WLYbiI70EHzCiF6TIPzB9F4ok5lzZBWKKqDVZTzbhk8N0Heib57tKC6HHbvDzsuDyecFLzXB4wfo8U+nkDE/5cCSp3zOQo6FodaBozbPI66F9DHJQlN7U96+m6VkEQJOBY7DHVQDlnWpM/N1oxKIXwPQof8q8GaA0KdajN9opbP3JP3HOtl0+VRy1itTXSYjLpo7hqHGTNnKBBO/HEidbFKd40rgukdi3ojP1cyB01D9tTI0n04wdjL1nyvV6UOBG+zliyWkZo7npoQJjAfm2UIzQToLJ0+evKnt81HwdfXhn84hm7A+k5/FetkfCxnzRhnNtRsPL0yNbjxHPFlt7qmRuNpC+tgDJspWlxC/8UcqGosQcHRIKMlRyBw37c3QoFmZnGq1P3uAntN+gpcjxCUZ01Op4XmmuixUGfVoEiECr6cKNujRrYTof42pWmYyuwMZ79GhIcqV/1A1nfJZPPMNjpI8x+LJG2/61eodzFZbW3tT2+em+HB5xogBiQ+8HPpBPmcLszkWYfpeaOZAhlGh32OncU9jVpvdk/nvyaqPvfUyNlsXozMlRavgAUeq3YT+0wh+wB9OXfyoPkXJCoAI4fHkAqjOXVGGj7lob2um/pk+AooW44MVmesACBH7H5C0c61INWOQNfBRaHpEJD2gR0eE4L+ndUZJxrguwzrpLQZKV0Lk/em9YL5LBzeYGdOvkiAWIVNIk3dYqdtVl/VWvW0J5nCmSVgsZWhjfnr295HXXw+f71isr6LV1U33AWuBZs3m62MS5t1Ouo90Lpv1SgUNONqHmuh40oDmszgKEDjmI5iQMGyxzMxKSVVUGCSU94bpSV3jyhuqZjqIcp7IJxD5OHlmyVQHfiIxWKXVT7VIo5BIJEcbyZGsAet9OlX+RsL6nYM4XYdx3+iGRCVBHIh/lhoPr7divHPu/A3ISBIo0RufXQHCgy9jT+VnstmWag4HwLDbScPGKN7vufDl+5Ih47GQqH7SQPCQn8S9ZrbeoX5zPszTx8obsGgGGLqsxVRRxAtC0+Q44KTuz9ljSgaQtVX0p+7X6T9xEs/zFmQNKL9JzRopQ7S/2EdoTQPdh5PT4t3d1egu9OHa751O4if+cBNth904nm3F2bkPc9zH0KvJ2kx1oBC4GkOj0zN7jBPg1NkQibssuPc66PQ4sMjq/I1CPA6gofTPbpDmHT/F2KUE+m1uHHs78XzHgnzD/I2Z0tUJwkGfuqIoSdsctFkkxn54gL5CrDvJeCy0xM758P21AfnqBKeuqt+cD/P1sQBjp3WY15UQ8s+beSwKOb6X6vOT5GQuInopQDj9TLhai3YyRkySMa5bBZMhAlMNMtVNKW/Fs1fP+bZmjqZf4kgyxjsUArFVGGWJqFTJPpuZ6Ov12I+r9rGhBffXQ9j3zw4ikmxE9/sAUa2R0i9FkR7bR+uWKN56O33qM/oTTvq/WcLgt9oZUlUVknadkdK0Ebz6O1fXcy1K6L3wgmZxk/cObSLSa8N1ZiHvzNbse6nmPxYyDZ2dGN+zYTtWgFFhNn3sMSe9u2Cg/sD1kx3iXqr8UsLJ2Rd1vGAylpyNmZq5SW+QqW7KuQHGwjo21aTPJhhpOdiJ0+WgbjJEYDyKZecmtLExvOpgAxgelElcmGNUsqEFd6cTt72O2KUAgU8sVJdriZ31zg42SFi/VoZybnBRgw2A+fE66nY10druxNnupG3X9ZeL5sfraNjjwNnupLW+DuujmxZ2t//6OpzPbyXuO5SnYDOHbI7FhhpMcojzJzbhcFjTFpfmQ3Z9rPqRMrjgI9DooLUIH0ehtmQCTv6E6ekfJX5/Tdo9PRIaDcTO+RiSZCr37qPqT67g/d7Ls2cK1tfRYIxwamqaNZ2koeRaDP/IEJJcicNRRellL4cOzdoLlDdQ8ZUJvPPMahTCcLcd+3CYxNUIMUB+wEp6OB7utmP76QTKxSGabXbaf+Al6/GAZMHxD1WsereHA8dvLkUs17vpeEqnLp5btsdCKaG0zUT0jalp6nzJso9dg8RKM3u0Exw9l15RnFZotdoX1YVF58Mx3v/jSp6uvpOJfx1nkjDjH9+G0VTO9ofN6H7zM45+9ygjc1zXS/fcybWf9/Hmb9U1wJVxIrcZMZVv55HNOj46fZSXjo4wazeSBcc/Wpg8sY8fXcw4IV4wxietGEJdjEsW7vnKKlb97jV+fimt/q/+lj//6DDeXy3k8xqoe8nGxskfc+i7w7O/h4VYX0f706Vc+tEQ/t+pKwE2sn07jLyRyvBncyw+HuNno0HCZ19jJO1vzY/s+tiFN4c5f+V9Rn569voAeP92tjPCyLvphbe+JZPDKQTDzgaMl3oYyvNDuNR0j9VhiQ0xcDa/59TsSTQcciO90kzPvR14vmGAi0M0vjB11p+p78pixXWSAetLDqo0Pvbvvbnpb2lzA849lZR+mP6Z1ExU7QTvTxZ/xJgX5VVU4cVbZKOeZXBJNSP4k8IHG4DI6b4lFGwAKtGvDHN+HJSTv2BCAc16M9Y1afVSmEDWwUbCsreN6tuDN7HWRov+0WpaXR562yrRSwlC787MVM7mL95gA3Cu+IINy22EI6Rsc+DZPkHjC8n0tcnmwbFFS+xtF42d/ln18zHsdrPvCT3xcIjI79W1mZXcpkP35RI0K1U3eygBetQzN8Itb1mNcIQk40aZaHDmv7J/cIwwoN1QReUc9ZlI2xy0PaFHA0iyHv26hW3y7dLsYAMol8ZEsClCYoSz7MyVn5GwvuShej0EX93PlYoWSo4tJH8jCNkRI5xlZ678jMLAcAAFDYYtDehXJPM7gpBrIuAsN9vK0P12glnLGN96hdEwIOspjU3MXo8kCDkgAs6yImHZYiAenn1bKYQZeDtIAriSZf5GEBZKBJxlosLWTf+JXppMErptHfR7HFSp2iSnyCOEp5/SJwi5JZLGQo4ZsO6tgX92MbDAO8QluZKGXTp8h/rmeLSHUAzECEfIrTVmjHdriP+vuiKD8ibcR7pxtlmpuLd0YTeKCrcUMcIRlo7dbk5ujdH1jEskrYuUGOEIOWPY2Yr7cDcd+f5FBOGWJUY4Qm5I1bTuSdAzacGzIUCzrQe+6aRja6m6ZZoo53vsM49lECOcoicCjpAbayxYdGPItb2Y37fR7Mn6CTozRMApeuKSSsiNyz58ESub7grjP5UKNqv1s37SRr3J+X3snrDEiIAj5Izx6ybk/z7PwF84cNRKSF8S0US4nrikEnLG2NxN69owoU+iePcfnf5p2/lV0uKyoNeWIq+OE7kUIfiWna5/UbcTbnUi4Ag5pV2nh0sL+xliYfkQAUcQhIIRORxBEApGBBxBEApGBBxBEApGBBxBEApGBBxBEApGBBxBEApGBBxBEApGBBxBEArm/wGHxYWNUNotKQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "39af7dab",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (L1Loss)\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9900b",
   "metadata": {},
   "source": [
    "Compared to MSE, L1 loss is generally considered less sensitive to outliers because it doesn't square the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad6b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Loss: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn_l1 = nn.L1Loss()\n",
    "predictions = torch.tensor([[1.0], [2.5], [0.0]], requires_grad=True)\n",
    "targets = torch.tensor([[1.2], [2.2], [0.5]])\n",
    "\n",
    "loss_l1 = loss_fn_l1(predictions, targets)\n",
    "print(f\"L1 Loss: {loss_l1.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f33dc",
   "metadata": {},
   "source": [
    "### Classification Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307bd00",
   "metadata": {},
   "source": [
    "#### Cross-Entropy Loss (CrossEntropyLoss) `torch.nn.CrossEntropyLoss`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42454da4",
   "metadata": {},
   "source": [
    "* Applying a `LogSoftmax`function to the model's raw output scores (logits). Softmax converts logits into probabilities that sum to 1, and LogSoftmax takes the logarithm of these probabilities.\n",
    "* Calculating the Negative Log Likelihood Loss (`NLLLoss`) between the LogSoftmax outputs and the target class indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3191bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss: 1.553871512413025\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# Example: Batch of 3 samples, 5 classes\n",
    "# Raw scores (logits) from the model\n",
    "predictions_logits = torch.randn(3, 5, requires_grad=True)\n",
    "# True class indices (must be LongTensor)\n",
    "targets_classes = torch.tensor([1, 0, 4]) # Class indices for the 3 samples\n",
    "\n",
    "loss_ce = loss_fn_ce(predictions_logits, targets_classes)\n",
    "print(f\"Cross-Entropy Loss: {loss_ce.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c34489",
   "metadata": {},
   "source": [
    "#### Binary Cross-Entropy Loss (BCELoss and BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "252957ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE With Logits Loss: 0.46984708309173584\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn_bce_logits = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Example: Batch of 4 samples, 1 output node (binary classification)\n",
    "predictions_logits_bin = torch.randn(4, 1, requires_grad=True) # Raw logits\n",
    "# Targets should be floats (0.0 or 1.0)\n",
    "targets_bin = torch.tensor([[1.0], [0.0], [0.0], [1.0]])\n",
    "\n",
    "loss_bce = loss_fn_bce_logits(predictions_logits_bin, targets_bin)\n",
    "print(f\"BCE With Logits Loss: {loss_bce.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230682b",
   "metadata": {},
   "source": [
    "## Building a Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21e3ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (layer_1): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (layer_2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the network structure\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNet, self).__init__() # Initialize the parent class\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        # Note: We don't apply Sigmoid here if using BCEWithLogitsLoss later\n",
    "        return out\n",
    "\n",
    "# Define network parameters\n",
    "input_features = 2\n",
    "hidden_units = 10\n",
    "output_classes = 1 # Single output for binary classification logit\n",
    "\n",
    "# Instantiate the network\n",
    "model = SimpleNet(input_features, hidden_units, output_classes)\n",
    "\n",
    "# Print the model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff3ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using loss: BCEWithLogitsLoss()\n",
      "Using optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation (Example Placeholder) ---\n",
    "# Imagine we have some input data (X) and target labels (y)\n",
    "# For this example, let's create dummy tensors\n",
    "# A mini-batch of 5 samples, each with 2 features\n",
    "dummy_input = torch.randn(5, input_features)\n",
    "# Corresponding dummy labels (0 or 1) - need float for BCEWithLogitsLoss\n",
    "dummy_labels = torch.randint(0, 2, (5, 1)).float()\n",
    "\n",
    "# --- Instantiate Model, Loss, and Optimizer ---\n",
    "# Model already instantiated above: model = SimpleNet(...)\n",
    "\n",
    "# Loss function: Binary Cross Entropy with Logits\n",
    "# This loss is suitable for binary classification and expects raw logits as input\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer: Adam is a popular choice\n",
    "# We pass the model's parameters to the optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"\\nUsing loss: {criterion}\")\n",
    "print(f\"Using optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b18ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model outputs (logits) shape: torch.Size([5, 1])\n",
      "Calculated loss: 0.7202\n",
      "\n",
      "Gradients for layer_1 weights (sample):\n",
      "tensor([0., 0.])\n",
      "\n",
      "Updated layer_1 weights (sample):\n",
      "tensor([-0.5542, -0.6292], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# --- Simulate a Single Training Step ---\n",
    "\n",
    "# 1. Forward Pass: Get model predictions (logits)\n",
    "outputs = model(dummy_input)\n",
    "print(f\"\\nModel outputs (logits) shape: {outputs.shape}\")\n",
    "# print(f\"Sample outputs: {outputs.detach().numpy().flatten()}\") # Optional: view outputs\n",
    "\n",
    "# 2. Calculate Loss\n",
    "loss = criterion(outputs, dummy_labels)\n",
    "print(f\"Calculated loss: {loss.item():.4f}\") # .item() gets the scalar value\n",
    "\n",
    "# 3. Backward Pass: Compute gradients\n",
    "# First, ensure gradients are zeroed from previous steps (important in a real loop)\n",
    "optimizer.zero_grad()\n",
    "loss.backward() # Calculate gradients of loss w.r.t. model parameters\n",
    "\n",
    "# 4. Optimizer Step: Update model weights\n",
    "optimizer.step() # Update parameters based on calculated gradients\n",
    "\n",
    "# --- Inspect Parameters (Optional) ---\n",
    "# You can inspect gradients after the backward pass (before optimizer.step())\n",
    "print(\"\\nGradients for layer_1 weights (sample):\")\n",
    "print(model.layer_1.weight.grad[0, :]) # Access gradient of a specific parameter\n",
    "\n",
    "# Or inspect parameter values after the step\n",
    "print(\"\\nUpdated layer_1 weights (sample):\")\n",
    "print(model.layer_1.weight[0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
